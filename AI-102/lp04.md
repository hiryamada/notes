# ラーニングパス04 Azure Cognitive Speech Services を使用し、音声を処理して翻訳する

https://learn.microsoft.com/ja-jp/training/paths/process-translate-speech-azure-cognitive-speech-services/

■このラーニングパスで学習すること

- Azure Cognitive Servicesの「音声サービス」について理解する。
  - 「音声テキスト変換」: 音声をテキストに変換（文字起こし）
  - 「テキスト読み上げ」: テキストを音声に変換


## モジュール1 音声サービスを使用して音声対応アプリを作成する

■リソース

以下のいずれかを使用。

- 「音声」リソース
- 「Cognitive services マルチサービス アカウント」リソース

■Speech Studio

https://aka.ms/speechstudio/

音声サービスのAPIをすばやく試すことができるWebアプリ。

■音声テキスト変換 speech to text

https://learn.microsoft.com/ja-jp/azure/cognitive-services/speech-service/speech-to-text

オーディオをテキストにリアルタイムまたはオフラインで文字起こしできる。

リアルタイム変換（マイクなど）、またはバッチ変換（ファイルなど）が利用できる。

■テキスト読み上げ text to speech

https://learn.microsoft.com/ja-jp/azure/cognitive-services/speech-service/text-to-speech

テキストを人間のような合成音声に変換。

様々な音声（男性、女性など）が用意されている。

[voiceNameの一覧](https://learn.microsoft.com/ja-jp/azure/cognitive-services/speech-service/language-support?tabs=tts#supported-languages) （「テキスト読み上げ」タブ内の`ja-JP`の行）

```
ja-JP-AoiNeural (女性)
ja-JP-DaichiNeural (男性)
ja-JP-KeitaNeural (男性)
ja-JP-MayuNeural1 (女性)
ja-JP-NanamiNeural (女性)
ja-JP-NaokiNeural (男性)
ja-JP-ShioriNeural (女性)
```

■SSML (Speech Synthesis Markup Language)による制御

https://learn.microsoft.com/ja-jp/training/modules/transcribe-speech-input-text/6-speech-synthesis-markup

音声合成マークアップ言語 (SSML) を使用すると、音声出力をより細かく制御できる。

```
<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" 
                     xmlns:mstts="https://www.w3.org/2001/mstts" xml:lang="en-US"> 
    <voice name="en-US-AriaNeural"> 
        <mstts:express-as style="cheerful"> 
          I say tomato 
        </mstts:express-as> 
    </voice> 
</speak>
```

たとえば`<mstts:express-as style="cheerful"> `で、「肯定的で幸せそうな語調」となる。

https://learn.microsoft.com/ja-jp/azure/cognitive-services/speech-service/speech-synthesis-markup-voice#speaking-styles-and-roles


## モジュール2 音声を音声サービスで翻訳する

https://learn.microsoft.com/ja-jp/training/modules/translate-speech-speech-service/?ns-enrollment-type=learningpath&ns-enrollment-id=learn.wwl.process-translate-speech-azure-cognitive-speech-services

音声の翻訳は、音声入力を認識して指定された言語に変換し、1 つ以上の他の言語でのトランスクリプトの翻訳を返すことにより、音声認識を構築します。

■リソース

専用の "音声" リソースまたはマルチサービスの "Cognitive Services" リソースのいずれかを使用。


## ラボ

- [ラボ07 音声の認識と合成](lab07cs.md)
- [ラボ08 音声の翻訳](lab08cs.md)

<!--
■ ラボ手順書

英語版（最新。ブラウザの翻訳機能で日本語化して閲覧できます）
https://github.com/MicrosoftLearning/AI-102-AIEngineer

日本語翻訳版（若干古い可能性があります）
https://github.com/MicrosoftLearning/AI-102-AIEngineer.ja-jp

ラボのファイル（ダウンロードして展開すると Allfiles フォルダ以下にラボで使用するファイルがあります）
https://github.com/MicrosoftLearning/AI-102-AIEngineer/archive/refs/heads/master.zip

■ ラボの概要
-->


■まとめ

- Azure Cognitive Servicesの「音声サービス」について学習しました。
  - 「音声テキスト変換」: 音声をテキストに変換（文字起こし）
  - 「テキスト読み上げ」: テキストを音声に変換

