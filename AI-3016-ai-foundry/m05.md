# 微調整された言語モデルを Azure AI Studio 内のコパイロットと統合する

https://learn.microsoft.com/ja-jp/training/modules/finetune-model-copilot-ai-studio/


## ファインチューニング（fine-tuning, 微調整）とは？

https://learn.microsoft.com/ja-jp/azure/ai-services/openai/how-to/fine-tuning

ファインチューニング と呼ばれるプロセスを使用して、個人用データセットに合わせてモデルを調整できる。

- プロンプト エンジニアリングからだけでは得られないより高品質な結果
- モデルの最大要求コンテキスト制限を超える多くの例を使用してトレーニングする機能。
- 短いプロンプトによるトークンの節約
- 低遅延の要求 (特に小規模なモデルを使用する場合)

## なぜファインチューニングを行うのか？


## ファインチューニングの手順

- トレーニングデータを準備する .jsonl 形式
- ファインチューニングジョブを作成する
- ジョブが完了すると gpt-35-turbo-0125.ft-abcd1234-ft-travel といった名前のモデルができる
- モデルをデプロイする


## ファインチューニング vs Few-shot学習

## ファインチューニング vs プロンプトエンジニアリング

## ファインチューニング vs RAG


## ファインチューニングが可能なモデルとリージョン

https://learn.microsoft.com/ja-jp/azure/ai-services/openai/concepts/models#fine-tuning-models

すべてのモデルがすべてのリージョンでファインチューニング可能なわけではない。
ファインチューニングが可能なモデルとリージョンの組み合わせは限られている。

可能な組み合わせの例:

- gpt-35-turbo (0125)
    - 米国東部 2
    - 米国中北部
    - スウェーデン中部
    - スイス西部
- gpt-4 (0613) 1	米国中北部
    - スウェーデン中部

## ファインチューニングを行うためのロール

Cognitive Services OpenAI 共同作成者


## ファインチューニングに要する時間

ラボ3番の例では、gpt-35-turboのファインチューニングに50分ほどかかる。

## ファインチューニングの費用


