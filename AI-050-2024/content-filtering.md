■Azure OpenAI Serviceのコンテンツフィルターとは？

GPTやDALL-E等において、不適切な入力や出力に対するフィルタリングを行う。

入力のフィルタリングの例: 「爆弾の作り方を教えて下さい」といったプロンプトがフィルタリングされる。GPTにそのようなプロンプトが送信されない（回答も生成されない）。

出力のフィルタリングの例: GPTやDALL-Eが不適切な回答を生成した場合、それがフィルタリングされ、出力されない（生成されたテキストがレスポンスには含まれない）。

■フィルタリングはどのように実行されるのか？

コンテンツフィルターにより、入力や出力が「性的」「暴力」「自傷行為」「ヘイトと公平性」の4つのカテゴリに該当するかどうか判定される。

※ヘイトと公平性: 軽蔑的・差別的なコンテンツ。たとえば特定の国や民族、特定のグループに対する嫌悪・差別など。

各カテゴリでは「安全」「低」「中」「高」の「重大度レベル」が決定される。

例「爆弾の作り方を教えて下さい」→「暴力（中）」

デフォルトのコンテンツフィルターでは、「安全」「低」は許可するが「中」「高」は禁止（フィルタリング）となっている。

どのようなカテゴリと重大度レベルでフィルタリングされたのかは、APIのレスポンスで返される。

■コンテンツフィルターの調節はできるか？

Yes。カスタムのコンテンツフィルターを作成すると、各カテゴリの「重大度しきい値」を調節できる。

たとえば、「暴力」カテゴリの「安全」「低」「中」は許可するが「高」は禁止、といったように調節ができる。

■カスタムのコンテンツフィルターはどうやって作るのか？

Azure OpenAI Studioで簡単に作成できる。

■カスタムのコンテンツフィルターの「追加モデル」

カスタムのコンテンツフィルターでは、以下のような「追加のモデル」も利用できる。これらはオプションであり、個別に有効・無効を設定可。不要ならばすべてオフでもよい。

|モデルの名称|概要|
|-|-|
|脱獄攻撃に対するプロンプトシールド|脱獄（開発者が設定したプロンプトの無効化など）の試行を検出|
|間接的な攻撃に対するプロンプト シールド|第三者が、生成型 AI システムがアクセスして処理できるドキュメント内に悪意のある命令を配置する「間接攻撃」を検出|
|保護された素材テキスト|既知のテキスト コンテンツ (例: 曲の歌詞、記事、レシピ、選択した Web コンテンツなど) に一致するコンテンツを検出|
|保護された素材コード|パブリック リポジトリから一連のソース コードに一致するソース コードを検出|

■カスタムのコンテンツフィルターの「ブロックリスト」

カスタムのコンテンツフィルターでは、使用を避ける「キーワード」や「Webサイト」を指定できる。これもオプションである。

■コンテンツフィルターは必須か？

Yes。デプロイ作成時に、デフォルトのコンテンツフィルターを選択するか、
カスタムのコンテンツフィルターを作成してそれを選択する。

■コンテンツフィルターはオフにできるか？

No。すべてのデプロイで、デフォルトまたはカスタムのコンテンツフィルターが使用される。


■カスタムのコンテンツフィルターを作成するとAzureリソースが作成されるか？

No。（「デプロイ」に対応するAzureリソースが作成されないのと同様、）「コンテンツフィルター」のAzureリソースも作成されない。

■コンテンツフィルターのコストは？

無料（現在、ドキュメントや価格のページで料金に関する説明がない）

■コンテンツフィルターの使用によって入力・出力のトークン数は変化するか？

No。トークン数は変わらない。

■コンテンツフィルターによる回答の精度への影響はあるか？

No。GPT等への入力と出力に対するフィルターであり、GPT等のモデルの動作や出力には影響がない。入力や出力を書き換えるものではない。

■コンテンツフィルターによる性能への影響はあるか？

No。GPT等への入力と出力に対するフィルターであり、GPT等のモデルの動作には影響がない。オフにすることはできないため、オン・オフで性能を調節するような仕組みではない。

なお、カスタムコンテンツフィルターでは、「ストリーミングモード」（非同期フィルター）を有効にすることで、チャンク単位ではなくトークン単位でのフィルタリングを実行できる。これによりストリーミング出力がトークン単位となるため、（見た目として）より細かい単位で連続的に出力される。出力がスピードアップするわけではないが、ユーザーの感覚としてはよりスムーズにテキストが出力されているように感じられる。

参考: https://qiita.com/nohanaga/items/4cd9e426e04a75bdc987

■コンテンツフィルターによってブロックされた場合どのような挙動になるか？

チャットプレイグラウンドでは、以下のような文章が返される。

```
Azure OpenAI のコンテンツ フィルタリング システムがトリガーされたため、プロンプトはフィルター処理されました。
理由: このプロンプトには次のフラグが付いたコンテンツが含まれています 自傷行為 (medium), 暴力 (medium)
プロンプトを変更して、もう一度お試しください。 
```

API呼び出しの場合は、フィルタリングがされたかどうか（finish_reason: content_filter）や、
どの理由でフィルターされたか（content_filter_results: ...）といった情報がレスポンスに含まれる。
アプリ側でその情報を使って、ユーザー向けのわかりやすいエラーメッセージを表示したりできる。

参考: https://blog.shibayan.jp/entry/20230626/1687713413

■「Azure AI Content Safety」との関係は？

「Azure AI Content Safety」は画像やテキスト内の憎悪、暴力、性的、自傷行為のコンテンツを検出するサービス。

2023/5/24にパブリックプレビューとなった。

https://azure.microsoft.com/ja-jp/updates/announcing-azure-ai-content-safety/

Azure OpenAI Serviceのコンテンツ フィルターは、内部的には、「Azure AI Content Safety」 を使用している。

https://learn.microsoft.com/ja-jp/azure/ai-services/openai/concepts/content-filter

■Azure OpenAI Serviceのコンテンツ フィルターと「Azure AI Content Safety」は何が違うのか？

機能的には同じもの。

Azure OpenAI Serviceのコンテンツ フィルターはAzure OpenAI Serviceのデプロイと常にセットで使用されるものであり、コンテンツ フィルター部分だけを任意のアプリから利用することはできない。コンテンツ フィルターのAzureリソースは作成されない（コンテンツフィルターはAzure OpenAI Serviceのリソースの一部）。

「Azure AI Content Safety」は任意のアプリと組み合わせて利用できる。「Azure AI Content Safety」のリソースを作成し、API経由で任意のアプリからコンテンツを送信して、不適切なコンテンツかどうかを判定できる。
