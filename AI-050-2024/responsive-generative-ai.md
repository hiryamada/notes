■生成AIの利用にはどのようなリスクがあるか？

たとえば、ユーザーが食材を入力すると、その食材を使った料理のレシピを生成するAIアプリを作るとする。
食材の加熱時間が不十分であるレシピが生成されると、そのレシピに沿って料理を作って食べた人が病気になったり死亡したりする可能性がある。

このように、生成AIを使ったアプリやシステム（生成AIソリューション）には「潜在的なリスク」（隠れたリスク）がある。

※「潜在的」＝表に現れていないもの。反対語は「顕在的」＝表に現れているもの。

※「リスク」＝悪いことが起こる可能性。

■開発者は生成AIの潜在的リスクにどう対処すればよいのか？

マイクロソフトの専門家が定義した「Azure OpenAI モデルにおける責任ある AI プラクティスの概要」（Responsible AI practices for Azure OpenAI models）があるので、それを参考に、識別・測定・緩和・運用の4ステージを実行するとよい。

※プラクティス＝実践

「Azure OpenAI モデルにおける責任ある AI プラクティスの概要」: [Responsible AI practices for Azure OpenAI models](https://learn.microsoft.com/ja-jp/legal/cognitive-services/openai/overview)

■「責任ある生成AIガイドライン」の4ステージでは何をすればよいのか？

以下の表を参照。

※「害（harm）」＝人間に対する身体的・健康的な傷害や、財産や環境に対する損害など。


| ステージ名         | 作業名称                        | 作業内容                               |
|--------------------|--------------------------------|-----------------------------------|  
| ステージ 1: 識別   | 潜在的な害の識別                | ソリューションの計画に関連する潜在的な害を特定する。    |  
|                    | 害の優先順位付け                | 特定された害の発生頻度と影響度を評価し、優先順位を設定する。|  
|                    | 害のテストと検証                | 優先順位付けされた害が実際に発生するかどうかをテストし、条件を確認する。|  
|                    | 害の文書化と共有                | 特定された害の詳細を文書化し、ステークホルダーと共有する。|  
| ステージ 2: 測定   | 入力プロンプトの準備            | 特定された害を引き起こす可能性のある多様な入力プロンプトを準備する。|  
|                    | 出力の生成                      | 準備したプロンプトをシステムに送信し、生成された出力を取得する。|  
|                    | 有害な結果の測定                | 事前定義された基準を使用して出力を評価し、有害な結果を分類する。|  
| ステージ 3: 緩和   | モデル層での緩和                | 適切なモデルの選択や、独自のトレーニングデータでのファインチューニングを行う。|  
|                    | セーフティシステム層での緩和    | コンテンツフィルターの設定や、悪用検出アルゴリズムの実装を行う。|  
|                    | メタプロンプトとグラウンド層での緩和 | システム入力の定義や、信頼できるデータソースからのコンテキストデータの取り込みを行う。|  
|                    | ユーザーエクスペリエンス層での緩和  | 入力と出力の検証や、システムの機能と制限に関する透明性のあるドキュメントの提供を行う。|  
| ステージ 4: 運用   | プレリリースレビューの完了      | リリース前に、法務、プライバシー、セキュリティ、アクセシビリティなどのコンプライアンスレビューを実施する。|  
|                    | ソリューションのリリースと運用  | フェーズごとのリリース計画を立て、インシデント対応計画やロールバック計画を作成する。また、ユーザーからのフィードバックを受け取る仕組みや、テレメトリーデータを追跡する仕組みを実装する。|  

■メタプロンプトとは？

メタプロンプト（Metaprompt）は、生成型AIモデルに対して特定の行動や出力を指示するために使用される指示やガイドラインのこと。

AIモデルに対して「どのように考えるべきか」、「どのようなスタイルやトーンで応答すべきか」、「どのような制約の下で動作すべきか」を伝えるもの。

行動の設定: モデルが特定の方法で応答するように指示する。
例: 「優しいトーンで回答してください」や「簡潔に答えてください」など。

内容の制約: モデルが出力する情報の範囲を制限する。
例: 「政治に関する質問には答えないでください」や「事実に基づいた情報を提供してください」など。

スタイルの設定: 出力の文体や形式を指定する。
例: 「学術的なトーンで書いてください」や「子供向けに簡単な言葉で説明してください」など。

特定のタスクの指示: モデルに特定のタスクを実行させるための指示。
例: 「次の文章を要約してください」や「以下のリストをアルファベット順に並べ替えてください」など。

※実際には、メタプロンプトは「システムメッセージ」で設定したり、ユーザーの入力したプロンプトにアプリ側でメタプロンプトを付け加えたりする。

「緩和」ステージでは、メタプロンプトを適切に設定して、有害な出力を防ぐ。

例: 「肉を使った料理」がユーザーのプロンプトだとすると、「生の肉を使ったレシピの場合は最低でも～度で～分以上しっかり加熱してください」といった制約（システムメッセージ）がメタプロンプトといえる。

